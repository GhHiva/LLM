x_true= [
    [1.0, 12.0, 31.5, 4.5],
    [4.0, 2.0, 3.5, 5.5],
    [10.0, 12.3, 1.5, 4],

]
y_true= [1.3, 9.7, 4.0]

N = Neuron(4)
M = MLP(4,[2,3,1])

y_pred= [M(x) for x in x_true]
print( f" y_pred is {y_pred}")

print('-----------------')

print(f" The weight of first neuron is {len(M.layer)}")

print('-----------------')

loss = sum([(yy-y)**2 for y,yy in zip(y_true, y_pred)], Value(0.0))
print(f" loss is {loss} ")

print('-----------------')

loss.backward()
print(draw_dot(loss).render('loss', format='png', cleanup= True))

-----------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------

x=[1,2,3]
N =Neuron(3)
print(f" N.W is {N.w},\n N.b is {N.b},\n N(x) is {N(x)}\n N.para is {N.para()}")
print('------------')
L= Layer(3,2)
print(f" L.neu is {L.neu}\n L(x) is {L(x)}\n L.para is {L.para()}")
print('------------')
M =MLP(3,[2,3,1])
print(f" M.layer are:{M.layer}\n M(x) is {M(x)}\n M.para is {M.para()} ")
# # print(draw_dot(M(x)).render('M', format='png', cleanup= True))

print(f" len N.para is {len(N.para())}")
print('------------')

print(f" len L.para is {len(L.para())}")
print('------------')

print(f" len MLP.para is {len(M.para())}")

len  N.para is 4 ==> 3+1
------------
len L.para is 8 ==> (3+1)*2
------------
len MLP.para is 21 ==> (4*2)+(3*3)+(4*1)

